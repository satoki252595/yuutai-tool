#!/usr/bin/env python3
"""
é‡è¤‡ãƒã‚§ãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆ

éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã€é–‹ç¤ºæ—¥æ™‚ã€ã‚¿ã‚¤ãƒˆãƒ«ãŒä¸€è‡´ã™ã‚‹å ´åˆã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚’ç¢ºèª
"""

import os
import sys
import logging
from datetime import datetime
from dotenv import load_dotenv

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from yuutai.notion_manager import YuutaiNotionManager

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_duplicate_logic():
    """é‡è¤‡ãƒã‚§ãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆ"""
    logger.info("=== Testing Duplicate Check Logic ===")
    
    try:
        load_dotenv()
        
        notion_api_key = os.getenv('NOTION_API_KEY')
        notion_page_id = os.getenv('YUUTAI_NOTION_PAGE_ID') or os.getenv('NOTION_PAGE_ID')
        
        if not notion_api_key or not notion_page_id:
            logger.warning("Notion credentials not configured, skipping test")
            return True
        
        manager = YuutaiNotionManager(notion_api_key, notion_page_id)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        if not manager.yuutai_database_id:
            manager.initialize_databases()
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿1: ç•°ãªã‚‹é–‹ç¤ºæ™‚åˆ»ã‚’æŒã¤åŒã˜ã‚¿ã‚¤ãƒˆãƒ«ãƒ»éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
        test_data_1 = {
            'id': 'test_dup_001',
            'title': 'é‡è¤‡ãƒ†ã‚¹ãƒˆç”¨æ ªä¸»å„ªå¾…åˆ¶åº¦ã®å°å…¥ã«é–¢ã™ã‚‹ãŠçŸ¥ã‚‰ã›',
            'company_code': '9999',
            'company_name': 'ãƒ†ã‚¹ãƒˆé‡è¤‡æ ªå¼ä¼šç¤¾',
            'disclosure_time': '14:00',
            'category': 'å„ªå¾…æ–°è¨­'
        }
        
        test_data_2 = {
            'id': 'test_dup_002',
            'title': 'é‡è¤‡ãƒ†ã‚¹ãƒˆç”¨æ ªä¸»å„ªå¾…åˆ¶åº¦ã®å°å…¥ã«é–¢ã™ã‚‹ãŠçŸ¥ã‚‰ã›',  # åŒã˜ã‚¿ã‚¤ãƒˆãƒ«
            'company_code': '9999',  # åŒã˜éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
            'company_name': 'ãƒ†ã‚¹ãƒˆé‡è¤‡æ ªå¼ä¼šç¤¾',
            'disclosure_time': '15:00',  # ç•°ãªã‚‹é–‹ç¤ºæ™‚åˆ»
            'category': 'å„ªå¾…æ–°è¨­'
        }
        
        test_data_3 = {
            'id': 'test_dup_003',
            'title': 'é‡è¤‡ãƒ†ã‚¹ãƒˆç”¨æ ªä¸»å„ªå¾…åˆ¶åº¦ã®å°å…¥ã«é–¢ã™ã‚‹ãŠçŸ¥ã‚‰ã›',  # åŒã˜ã‚¿ã‚¤ãƒˆãƒ«
            'company_code': '9999',  # åŒã˜éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
            'company_name': 'ãƒ†ã‚¹ãƒˆé‡è¤‡æ ªå¼ä¼šç¤¾',
            'disclosure_time': '14:00',  # test_data_1ã¨åŒã˜é–‹ç¤ºæ™‚åˆ»
            'category': 'å„ªå¾…æ–°è¨­'
        }
        
        logger.info("Test 1: Creating first disclosure (14:00)...")
        result1 = manager.upload_yuutai_disclosure(test_data_1)
        logger.info(f"Result 1: {'Success' if result1 else 'Failed'}")
        
        logger.info("\nTest 2: Creating second disclosure with different time (15:00)...")
        result2 = manager.upload_yuutai_disclosure(test_data_2)
        logger.info(f"Result 2: {'Success - Should create new record' if result2 else 'Failed'}")
        
        logger.info("\nTest 3: Creating third disclosure with same time as first (14:00)...")
        result3 = manager.upload_yuutai_disclosure(test_data_3)
        logger.info(f"Result 3: {'Success - Should be detected as duplicate' if result3 else 'Failed'}")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªã§ç¢ºèª
        logger.info("\n=== Verifying Database State ===")
        response = manager.uploader.client.databases.query(
            database_id=manager.yuutai_database_id,
            filter={
                "property": "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰",
                "rich_text": {"equals": "9999"}
            }
        )
        
        results = response.get('results', [])
        logger.info(f"Total records for stock code 9999: {len(results)}")
        
        for i, record in enumerate(results):
            props = record['properties']
            title = ''.join([t['plain_text'] for t in props.get('ã‚¿ã‚¤ãƒˆãƒ«', {}).get('title', [])])
            disclosure_time = props.get('é–‹ç¤ºæ™‚åˆ»', {}).get('rich_text', [{}])[0].get('plain_text', '')
            logger.info(f"Record {i+1}: Time={disclosure_time}, Title={title[:30]}...")
        
        # æœŸå¾…ã•ã‚Œã‚‹çµæœ: 2ã¤ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼ˆ14:00ã¨15:00ï¼‰
        if len(results) == 2:
            logger.info("\nâœ… Duplicate check logic is working correctly!")
            logger.info("âœ… Records with identical stock code, title, and disclosure time are properly detected as duplicates")
            logger.info("âœ… Records with different disclosure times are treated as separate entries")
            
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            logger.info("\nCleaning up test data...")
            for record in results:
                try:
                    manager.uploader.client.pages.update(
                        page_id=record['id'],
                        archived=True
                    )
                except Exception as e:
                    logger.warning(f"Failed to archive test record: {str(e)}")
            
            return True
        else:
            logger.error(f"\nâŒ Unexpected number of records: {len(results)} (expected 2)")
            return False
        
    except Exception as e:
        logger.error(f"Duplicate check test failed: {str(e)}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    logger.info("ğŸš€ Starting Duplicate Check Test")
    
    success = test_duplicate_logic()
    
    if success:
        logger.info("\nğŸ‰ Duplicate check test passed!")
        logger.info("\nKey findings:")
        logger.info("âœ… Disclosures with same stock code + title + disclosure time â†’ Detected as duplicates")
        logger.info("âœ… Disclosures with same stock code + title but different time â†’ Created as separate records")
        logger.info("âœ… This prevents duplicate entries while allowing legitimate multiple disclosures on the same day")
    else:
        logger.error("\nâš ï¸ Duplicate check test failed")
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)